{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "1e9b14b7-dd9c-41b0-98a2-1a9f6e396372",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\nimport nltk\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom sklearn.metrics import classification_report, confusion_matrix",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0cb93875-b6f9-41b8-b465-1d11157043ae",
      "cell_type": "code",
      "source": "load dataset\nresume_df = pd.read_csv('data/resume_data.csv', encoding = 'latin-1')\nresume_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "69c38e13-bac7-46e6-8403-e6cb9e8f0600",
      "cell_type": "code",
      "source": "resume_df = resume_df[['resume_text', 'class']]\nresume_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "82cd0a48-c75f-4b4a-ae33-49bba57e0795",
      "cell_type": "code",
      "source": "resume_df.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 125 entries, 0 to 124\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   resume_text  125 non-null    object\n 1   class        125 non-null    object\ndtypes: object(2)\nmemory usage: 2.1+ KB",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b29cbf6b-de9f-4695-add3-1fc76c9127df",
      "cell_type": "code",
      "source": "resume_df['class'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f9668502-a477-4615-81d1-aeb6a1daa7b5",
      "cell_type": "code",
      "source": "# HERE WE OBSERVE, WE HAVE NO NULL POINTS IN OUR DATASET\nresume_df['class'] = resume_df['class'].apply(lambda x:1 if x == 'flagged' else 0)\nresume_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "37c12963-1a1c-4bb8-b390-a267604209a3",
      "cell_type": "code",
      "source": "# data cleansing\n\nresume_df['resume_text'] = resume_df['resume_text'].apply(lambda x: x .replace('\\r', ''))\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\n\nstop_words = stopwords.words('english')\n\nstop_words.extend(['from', 'subject', 'edu', 're', 'use', 'email', 'com'])\n\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n            result.append(token)\n    return ' '.join(result)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8c1eb17b-f90f-4f21-a49b-c887907dd37b",
      "cell_type": "code",
      "source": "resume_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "22c326dd-1b93-48e5-8ccd-681a1f7545c5",
      "cell_type": "code",
      "source": "resume_df['cleaned'] = resume_df['resume_text'].apply(preprocess)\n\nresume_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "12c5e76e-6143-46d0-8cad-829d9785714d",
      "cell_type": "code",
      "source": "resume_df['cleaned'][0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b1edb858-958a-4606-9981-a0caaa517a7e",
      "cell_type": "code",
      "source": "# PLOTTING COUNTS OF SAMPLE LABELLED AS 1 AND 0\nsns.countplot(resume_df['class'], label = 'Count Plot')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "43c0f6aa-7440-45a4-9177-5fe88296e71c",
      "cell_type": "code",
      "source": "# PLOTTING THE WORDCLOUD:\n\n# 1) FOR CLASS 1:\n\n%matplotlib inline\n\nplt.figure(figsize = (20, 20))\n\nwc = WordCloud(max_words = 2000, width = 1600, height = 800, stopwords = stop_words).generate(str(resume_df[resume_df['class']==1].cleaned))\n\nplt.imshow(wc)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "902dbd9b-12db-4fc4-b808-df4a9c1734ba",
      "cell_type": "code",
      "source": "#1) FOR CLASS 0:\n\n%matplotlib inline\n\nplt.figure(figsize = (20, 20))\n\nwc = WordCloud(max_words = 2000, width = 1600, height = 800, stopwords = stop_words).generate(str(resume_df[resume_df['class']==0].cleaned))\n\nplt.imshow(wc)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ebe60dbc-9d7f-4037-81a1-1d4ffd05d651",
      "cell_type": "code",
      "source": "# CONVERTING SENTENCES INTO TOKENIZED FORMS AND THEN CONVERTING TO NUMERICAL VALUES IN ORDER FOR THE MODEL TO TRAIN:\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\ncountvectorizer = vectorizer.fit_transform(resume_df['cleaned'])\n\nprint(vectorizer.get_feature_names())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0a462097-c4b7-41ea-ac60-cd4df018c80a",
      "cell_type": "code",
      "source": "# PROCESSED DATA:\nprint(countvectorizer.toarray())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "91e4d108-3d30-41b9-b5bc-97bacb5f00d5",
      "cell_type": "code",
      "source": "TRAINING A NAIVE BAYES CLASSIFER\nX = countvectorizer\ny = resume_df['class']\n\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n\n\nfrom sklearn.naive_bayes import MultinomialNB\n\nBayes_clf = MultinomialNB(alpha = 3)\nBayes_clf.fit(X_train, y_train)  ## Training the model",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0299daff-ae61-40c6-8d46-91d535e54201",
      "cell_type": "code",
      "source": "ASSESING THE TRAINED MODEL\n%matplotlib inline\n\n# PLOTTING CONFUSION MATRIX:\n\n# 1) FOR TRAINING DATA\n\ny_pred_train = Bayes_clf.predict(X_train)\n\ncm = confusion_matrix(y_train, y_pred_train)\n\nsns.heatmap(cm, annot=True)\n\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a10108a1-ea82-4156-a13e-c39d2803d5b7",
      "cell_type": "code",
      "source": "%matplotlib inline\n\n# WE CAN SEE OUR MODEL PERFORMED REALLY WELL ON TRAINING DATA: IT CLASSFIED ALL OF THE POINTS CORRECTLY\n\n# 2) FOR TEST DATA:\n\ny_pred_test = Bayes_clf.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred_test)\n\nsns.heatmap(cm, annot=True)\n\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eb9b6b0e-dc7e-4a39-a0e3-57ca2fea73ba",
      "cell_type": "code",
      "source": "print(classification_report(y_test, y_pred_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8cb96120-a337-47de-8620-3c94c357a689",
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nprint(\"Accuracy of model on Train Dataset = {}\".format(accuracy_score(y_train, y_pred_train)))\nprint(\"Accuracy of model on Test Dataset = {}\".format(accuracy_score(y_test, y_pred_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ecd73144-4751-47b0-9345-3f38a71c01f9",
      "cell_type": "code",
      "source": "print(\"Accuracy of model is = {}\".format(accuracy_score(y_test, y_pred_test)))\nprint(\"F1 of model is = {}\".format(f1_score(y_test, y_pred_test)))\nprint(\"Precision of model is = {}\".format(precision_score(y_test, y_pred_test)))\nprint(\"Recall of model is = {}\".format(recall_score(y_test, y_pred_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}